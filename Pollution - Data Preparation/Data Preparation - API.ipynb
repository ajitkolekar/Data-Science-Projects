{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ajit Kolekar\n",
    "Data Preparation - Connecting to an API/Pulling in the Data and Cleaning/Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no API interface to get the data for all states at the same time. There is an API interface to get the data \n",
    "# by specific state. I determined that it might be better to get the data for all states one at a time and combine the \n",
    "# data. There is an interface to get a list of all valid state codes, that can be used to retrieve data by states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the APIkeys.json file and extract api key\n",
    "with open('APIkeys.json') as f:\n",
    "    keys = json.load(f)\n",
    "    aqsapi = keys['AQSapi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a variable for the url to get the list of all states \n",
    "states_url = 'https://aqs.epa.gov/data/api/list/states?email=akolekar@my365.bellevue.edu&key='+aqsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get api data for the url passed in as a parameter\n",
    "def get_api_data(url):\n",
    "    # Use requests library to get data using the url variable\n",
    "    response = requests.get(url)\n",
    "        \n",
    "    # Load the url data in json format\n",
    "    json_data=json.loads(response.text)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call get_api_data function for states_url and store the json data in the json_data variable \n",
    "json_data=get_api_data(states_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store state codes\n",
    "states = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the json data and get the state code value for each instance. Store the data in the states list.\n",
    "for i in range(len(json_data['Data'])):\n",
    "    states.append(json_data['Data'][i]['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56', '66', '72', '78', '80', 'CC']\n"
     ]
    }
   ],
   "source": [
    "# print the state codes and compare with the website to make sure the values are correct.\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "# Check the number of state codes and validate the count by comparing with the website. \n",
    "print(len(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to performance issues, spilt the states list in three lists\n",
    "states1 = states[0:20]\n",
    "states2 = states[20:40]\n",
    "states3 = states[40:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
      "['24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '44']\n",
      "['45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56', '66', '72', '78', '80', 'CC']\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the states are properly split \n",
    "print(states1)\n",
    "print(states2)\n",
    "print(states3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup headers list with the keys from the json data\n",
    "headers = ['address', 'cbsa_code', 'cbsa_name', 'city_name', 'close_date', 'concurred_exclusions', 'county_code',\n",
    "           'county_name', 'csa_code', 'csa_name', 'datum', 'dominant_source', 'elevation', 'last_method_begin_date',\n",
    "           'last_method_code', 'last_method_description', 'lat_lon_accuracy', 'latitude', 'local_site_name',\n",
    "           'longitude', 'measurement_scale', 'measurement_scale_def', 'monitor_type', \n",
    "           'monitoring_agency', 'monitoring_agency_code', 'monitoring_objective', 'naaqs_primary_monitor', \n",
    "           'networks', 'open_date', 'parameter_code', 'parameter_name', 'pl_probe_location', 'poc', 'probe_height', \n",
    "           'qa_primary_monitor', 'si_id', 'site_number', 'state_code', 'state_name', 'tribal_code', 'tribe_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process json data and extract values for each key for each county. The function should then \n",
    "# combine the processed data and headers list into a data frame and return the data frame. \n",
    "\n",
    "def process_json_data(json_data, headers):\n",
    "    county_list = []                                       # Empty list to store data of all counties of the state\n",
    "    for i in range(len(json_data['Data'])):                # Loop through all instances of 'Data' key \n",
    "        county_data = []                                   # Empty list to store data of a specific county data\n",
    "        for k in headers:                                  # Loop through all values in the headers list\n",
    "            county_data.append(json_data['Data'][0][k])    # Extract value of each header and add to the county_data list\n",
    "        county_list.append(county_data)                    # Add the county_data to the list of all counties\n",
    "        \n",
    "    # Print number of counties for each state if there are counties\n",
    "    if len(county_list) > 0:\n",
    "        print(\"There are {} counties in {}.\".format(len(county_list), county_list[0][-3]))\n",
    "    \n",
    "    # Use the rows from the county_list and the headers list to create a data frame state_df\n",
    "    state_df = pd.DataFrame(county_list, columns=headers)\n",
    "    \n",
    "    # Return the data frame\n",
    "    return state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1562 counties in Alabama.\n",
      "There are 833 counties in Alaska.\n",
      "There are 2776 counties in Arizona.\n",
      "There are 425 counties in Arkansas.\n",
      "There are 12366 counties in California.\n",
      "There are 3726 counties in Colorado.\n",
      "There are 735 counties in Connecticut.\n",
      "There are 369 counties in Delaware.\n",
      "There are 542 counties in District Of Columbia.\n",
      "There are 2699 counties in Florida.\n",
      "There are 2047 counties in Georgia.\n",
      "There are 332 counties in Hawaii.\n",
      "There are 644 counties in Idaho.\n",
      "There are 2570 counties in Illinois.\n",
      "There are 2711 counties in Indiana.\n",
      "There are 1658 counties in Iowa.\n",
      "There are 482 counties in Kansas.\n",
      "There are 2218 counties in Kentucky.\n",
      "There are 934 counties in Louisiana.\n",
      "There are 1004 counties in Maine.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty data frame using headers list as columns\n",
    "combined_df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# Setup the variables for url\n",
    "serviceurl1 = 'https://aqs.epa.gov/data/api/monitors/byState?email=akolekar@my365.bellevue.edu&key='\n",
    "serviceurl2 = '&bdate=20100101&edate=20160101&state='\n",
    "\n",
    "# Loop through the states1 list\n",
    "for i in range(len(states1)):\n",
    "    # Process the data only if the state value is numeric. The API will fail for non-numeric values. \n",
    "    if states1[i].isnumeric():\n",
    "        # Setup the url variable using key, state code, and other variables\n",
    "        url = serviceurl1+aqsapi+serviceurl2+states1[i]\n",
    "        \n",
    "        # Call get_api_data function using url to get the json data\n",
    "        json_data = get_api_data(url)\n",
    "        \n",
    "        # Create the frames list using combined_df and the df returned by process_json_data function\n",
    "        frames = [combined_df, process_json_data(json_data, headers)]\n",
    "        \n",
    "        # The state level data gets added to combined_df after every state is processed. Merge the dfs using concat method.\n",
    "        combined_df = pd.concat(frames)\n",
    "        \n",
    "        # Add a delay of 1 second between API calls to prevent connection issues  \n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40633, 41)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of counties after states1 list is processed\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1013 counties in Maryland.\n",
      "There are 1878 counties in Massachusetts.\n",
      "There are 2504 counties in Michigan.\n",
      "There are 3957 counties in Minnesota.\n",
      "There are 1167 counties in Mississippi.\n",
      "There are 1308 counties in Missouri.\n",
      "There are 898 counties in Montana.\n",
      "There are 339 counties in Nebraska.\n",
      "There are 667 counties in Nevada.\n",
      "There are 765 counties in New Hampshire.\n",
      "There are 1414 counties in New Jersey.\n",
      "There are 943 counties in New Mexico.\n",
      "There are 3244 counties in New York.\n",
      "There are 2534 counties in North Carolina.\n",
      "There are 475 counties in North Dakota.\n",
      "There are 3942 counties in Ohio.\n",
      "There are 2055 counties in Oklahoma.\n",
      "There are 2501 counties in Oregon.\n",
      "There are 5029 counties in Pennsylvania.\n",
      "There are 793 counties in Rhode Island.\n"
     ]
    }
   ],
   "source": [
    "# Setup the variables for url\n",
    "serviceurl1 = 'https://aqs.epa.gov/data/api/monitors/byState?email=akolekar@my365.bellevue.edu&key='\n",
    "serviceurl2 = '&bdate=20100101&edate=20160101&state='\n",
    "\n",
    "# Loop through the states2 list\n",
    "for i in range(len(states2)):\n",
    "    # Process the data only if the state value is numeric. The API will fail for non-numeric values. \n",
    "    if states2[i].isnumeric():\n",
    "        # Setup the url variable using key, state code, and other variables\n",
    "        url = serviceurl1+aqsapi+serviceurl2+states2[i]\n",
    "\n",
    "        # Call get_api_data function using url to get the json data\n",
    "        json_data = get_api_data(url)\n",
    "\n",
    "        # Create the frames list using combined_df and the df returned by process_json_data function\n",
    "        frames = [combined_df, process_json_data(json_data, headers)]\n",
    "\n",
    "        # The state level data gets added to combined_df after every state is processed. Merge the dfs using concat method.\n",
    "        combined_df = pd.concat(frames)\n",
    "        \n",
    "        # Add a delay of 1 second between API calls to prevent connection issues  \n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78059, 41)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of counties after states1 and states2 lists are processed\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1162 counties in South Carolina.\n",
      "There are 632 counties in South Dakota.\n",
      "There are 1346 counties in Tennessee.\n",
      "There are 8653 counties in Texas.\n",
      "There are 1310 counties in Utah.\n",
      "There are 730 counties in Vermont.\n",
      "There are 1498 counties in Virginia.\n",
      "There are 1826 counties in Washington.\n",
      "There are 758 counties in West Virginia.\n",
      "There are 1580 counties in Wisconsin.\n",
      "There are 1868 counties in Wyoming.\n",
      "There are 186 counties in Puerto Rico.\n",
      "There are 253 counties in Virgin Islands.\n",
      "There are 315 counties in Country Of Mexico.\n"
     ]
    }
   ],
   "source": [
    "# Setup the variables for url\n",
    "serviceurl1 = 'https://aqs.epa.gov/data/api/monitors/byState?email=akolekar@my365.bellevue.edu&key='\n",
    "serviceurl2 = '&bdate=20100101&edate=20160101&state='\n",
    "\n",
    "# Loop through the states3 list\n",
    "for i in range(len(states3)):\n",
    "    # Process the data only if the state value is numeric. The API will fail for non-numeric values. \n",
    "    if states3[i].isnumeric():\n",
    "        # Setup the url variable using key, state code, and other variables\n",
    "        url = serviceurl1+aqsapi+serviceurl2+states3[i]\n",
    "\n",
    "        # Call get_api_data function using url to get the json data\n",
    "        json_data = get_api_data(url)\n",
    "\n",
    "        # Create the frames list using combined_df and the df returned by process_json_data function\n",
    "        frames = [combined_df, process_json_data(json_data, headers)]\n",
    "\n",
    "        # The state level data gets added to combined_df after every state is processed. Merge the dfs using concat method.\n",
    "        combined_df = pd.concat(frames)\n",
    "        \n",
    "        # Add a delay of 1 second between API calls to prevent connection issues  \n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100176, 41)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of counties after all states are processed\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>close_date</th>\n",
       "      <th>concurred_exclusions</th>\n",
       "      <th>county_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>csa_code</th>\n",
       "      <th>csa_name</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_probe_location</th>\n",
       "      <th>poc</th>\n",
       "      <th>probe_height</th>\n",
       "      <th>qa_primary_monitor</th>\n",
       "      <th>si_id</th>\n",
       "      <th>site_number</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>tribal_code</th>\n",
       "      <th>tribe_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>None</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>None</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>None</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>None</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>None</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address cbsa_code  \\\n",
       "0  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
       "1  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
       "2  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
       "3  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
       "4  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
       "\n",
       "                   cbsa_name city_name  close_date concurred_exclusions  \\\n",
       "0  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17                 None   \n",
       "1  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17                 None   \n",
       "2  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17                 None   \n",
       "3  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17                 None   \n",
       "4  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17                 None   \n",
       "\n",
       "  county_code county_name csa_code                    csa_name  ...  \\\n",
       "0         003     Baldwin      380  Mobile-Daphne-Fairhope, AL  ...   \n",
       "1         003     Baldwin      380  Mobile-Daphne-Fairhope, AL  ...   \n",
       "2         003     Baldwin      380  Mobile-Daphne-Fairhope, AL  ...   \n",
       "3         003     Baldwin      380  Mobile-Daphne-Fairhope, AL  ...   \n",
       "4         003     Baldwin      380  Mobile-Daphne-Fairhope, AL  ...   \n",
       "\n",
       "  pl_probe_location poc  probe_height qa_primary_monitor si_id site_number  \\\n",
       "0              None  10          None                  Y     7        0010   \n",
       "1              None  10          None                  Y     7        0010   \n",
       "2              None  10          None                  Y     7        0010   \n",
       "3              None  10          None                  Y     7        0010   \n",
       "4              None  10          None                  Y     7        0010   \n",
       "\n",
       "   state_code  state_name tribal_code  tribe_name  \n",
       "0          01     Alabama        None        None  \n",
       "1          01     Alabama        None        None  \n",
       "2          01     Alabama        None        None  \n",
       "3          01     Alabama        None        None  \n",
       "4          01     Alabama        None        None  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first few records in the dataframe using head method.\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'cbsa_code', 'cbsa_name', 'city_name', 'close_date',\n",
       "       'concurred_exclusions', 'county_code', 'county_name', 'csa_code',\n",
       "       'csa_name', 'datum', 'dominant_source', 'elevation',\n",
       "       'last_method_begin_date', 'last_method_code', 'last_method_description',\n",
       "       'lat_lon_accuracy', 'latitude', 'local_site_name', 'longitude',\n",
       "       'measurement_scale', 'measurement_scale_def', 'monitor_type',\n",
       "       'monitoring_agency', 'monitoring_agency_code', 'monitoring_objective',\n",
       "       'naaqs_primary_monitor', 'networks', 'open_date', 'parameter_code',\n",
       "       'parameter_name', 'pl_probe_location', 'poc', 'probe_height',\n",
       "       'qa_primary_monitor', 'si_id', 'site_number', 'state_code',\n",
       "       'state_name', 'tribal_code', 'tribe_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the columns names to see if any column headings need to be changed\n",
    "\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names for City, County, and State\n",
    "\n",
    "combined_df.rename(columns={'city_name': 'City', \n",
    "                            'county_name': 'County',\n",
    "                            'state_name':'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'cbsa_code', 'cbsa_name', 'City', 'close_date',\n",
       "       'concurred_exclusions', 'county_code', 'County', 'csa_code', 'csa_name',\n",
       "       'datum', 'dominant_source', 'elevation', 'last_method_begin_date',\n",
       "       'last_method_code', 'last_method_description', 'lat_lon_accuracy',\n",
       "       'latitude', 'local_site_name', 'longitude', 'measurement_scale',\n",
       "       'measurement_scale_def', 'monitor_type', 'monitoring_agency',\n",
       "       'monitoring_agency_code', 'monitoring_objective',\n",
       "       'naaqs_primary_monitor', 'networks', 'open_date', 'parameter_code',\n",
       "       'parameter_name', 'pl_probe_location', 'poc', 'probe_height',\n",
       "       'qa_primary_monitor', 'si_id', 'site_number', 'state_code', 'State',\n",
       "       'tribal_code', 'tribe_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the column names are updated\n",
    "\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address                         0\n",
       "cbsa_code                    3686\n",
       "cbsa_name                    3686\n",
       "City                            0\n",
       "close_date                  42399\n",
       "concurred_exclusions       100176\n",
       "county_code                     0\n",
       "County                          0\n",
       "csa_code                    22629\n",
       "csa_name                    22629\n",
       "datum                           0\n",
       "dominant_source             66559\n",
       "elevation                       0\n",
       "last_method_begin_date          0\n",
       "last_method_code                0\n",
       "last_method_description         0\n",
       "lat_lon_accuracy                0\n",
       "latitude                        0\n",
       "local_site_name              7611\n",
       "longitude                       0\n",
       "measurement_scale           48663\n",
       "measurement_scale_def       48663\n",
       "monitor_type                44055\n",
       "monitoring_agency               0\n",
       "monitoring_agency_code          0\n",
       "monitoring_objective            0\n",
       "naaqs_primary_monitor       98399\n",
       "networks                    65519\n",
       "open_date                       0\n",
       "parameter_code                  0\n",
       "parameter_name                  0\n",
       "pl_probe_location           50946\n",
       "poc                             0\n",
       "probe_height                66965\n",
       "qa_primary_monitor          93510\n",
       "si_id                           0\n",
       "site_number                     0\n",
       "state_code                      0\n",
       "State                           0\n",
       "tribal_code                100176\n",
       "tribe_name                 100176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The missing values are identified as null and can be checked by using isnull() function. Find missing values for each column\n",
    "# and add them by using sum() function to determine how many missing values exist for each column.\n",
    "\n",
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns concurred_exclusions, dominant_source, naaqs_primary_monitor, networks, probe_height, \n",
    "# qa_primary_monitor, tribal_code, and tribe_name as more than half of the values in these columns are null\n",
    "\n",
    "del combined_df['concurred_exclusions']\n",
    "del combined_df['dominant_source']\n",
    "del combined_df['naaqs_primary_monitor']\n",
    "del combined_df['networks']\n",
    "del combined_df['probe_height']\n",
    "del combined_df['qa_primary_monitor']\n",
    "del combined_df['tribal_code']\n",
    "del combined_df['tribe_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'cbsa_code', 'cbsa_name', 'City', 'close_date',\n",
       "       'county_code', 'County', 'csa_code', 'csa_name', 'datum', 'elevation',\n",
       "       'last_method_begin_date', 'last_method_code', 'last_method_description',\n",
       "       'lat_lon_accuracy', 'latitude', 'local_site_name', 'longitude',\n",
       "       'measurement_scale', 'measurement_scale_def', 'monitor_type',\n",
       "       'monitoring_agency', 'monitoring_agency_code', 'monitoring_objective',\n",
       "       'open_date', 'parameter_code', 'parameter_name', 'pl_probe_location',\n",
       "       'poc', 'si_id', 'site_number', 'state_code', 'State'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the column names are deleted\n",
    "\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While there are other columns with some null values, it is important to not delete any rows since the rows are unique to\n",
    "# the combination of county and state. The columns, such as State, County, and City do not have any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City is duplicated - True\n",
      "State is duplicated - True\n",
      "County is duplicated - True\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate values in 'County' and 'State' columns\n",
    "\n",
    "print(\"City is duplicated - {}\".format(any(combined_df.City.duplicated())))\n",
    "print(\"State is duplicated - {}\".format(any(combined_df.State.duplicated())))\n",
    "print(\"County is duplicated - {}\".format(any(combined_df.County.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the 'State' value was duplicated for each corresponding county, it is obvious to have duplicate values for state.\n",
    "# It is also possible to have same county name or same city name in multiple states. \n",
    "# Since the duplicates are allowed, no additional action is needed to handle duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             address cbsa_code  \\\n",
      "0  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...     19300   \n",
      "\n",
      "                   cbsa_name      City  close_date county_code   County  \\\n",
      "0  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
      "\n",
      "  csa_code                    csa_name  datum  ...  monitoring_objective  \\\n",
      "0      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
      "\n",
      "    open_date parameter_code    parameter_name  pl_probe_location  poc si_id  \\\n",
      "0  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
      "\n",
      "   site_number state_code    State  \n",
      "0         0010         01  Alabama  \n",
      "\n",
      "[1 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first row in the data frame to understand the values in each column\n",
    "print(combined_df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>City</th>\n",
       "      <th>close_date</th>\n",
       "      <th>county_code</th>\n",
       "      <th>County</th>\n",
       "      <th>csa_code</th>\n",
       "      <th>csa_name</th>\n",
       "      <th>datum</th>\n",
       "      <th>...</th>\n",
       "      <th>monitoring_objective</th>\n",
       "      <th>open_date</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>pl_probe_location</th>\n",
       "      <th>poc</th>\n",
       "      <th>si_id</th>\n",
       "      <th>site_number</th>\n",
       "      <th>state_code</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fairhope High School, 1 Pirate Drive, Fairhope...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>...</td>\n",
       "      <td>POPULATION EXPOSURE</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>43236</td>\n",
       "      <td>2-Ethyl-1-butene</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fairhope High School, 1 Pirate Drive, Fairhope...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>...</td>\n",
       "      <td>POPULATION EXPOSURE</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>43236</td>\n",
       "      <td>2-Ethyl-1-butene</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fairhope High School, 1 Pirate Drive, Fairhope...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>...</td>\n",
       "      <td>POPULATION EXPOSURE</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>43236</td>\n",
       "      <td>2-Ethyl-1-butene</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fairhope High School, 1 Pirate Drive, Fairhope...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>...</td>\n",
       "      <td>POPULATION EXPOSURE</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>43236</td>\n",
       "      <td>2-Ethyl-1-butene</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fairhope High School, 1 Pirate Drive, Fairhope...</td>\n",
       "      <td>19300</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>2010-09-17</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>380</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>...</td>\n",
       "      <td>POPULATION EXPOSURE</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>43236</td>\n",
       "      <td>2-Ethyl-1-butene</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0010</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address cbsa_code  \\\n",
       "0  Fairhope High School, 1 Pirate Drive, Fairhope...     19300   \n",
       "1  Fairhope High School, 1 Pirate Drive, Fairhope...     19300   \n",
       "2  Fairhope High School, 1 Pirate Drive, Fairhope...     19300   \n",
       "3  Fairhope High School, 1 Pirate Drive, Fairhope...     19300   \n",
       "4  Fairhope High School, 1 Pirate Drive, Fairhope...     19300   \n",
       "\n",
       "                   cbsa_name      City  close_date county_code   County  \\\n",
       "0  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
       "1  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
       "2  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
       "3  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
       "4  Daphne-Fairhope-Foley, AL  Fairhope  2010-09-17         003  Baldwin   \n",
       "\n",
       "  csa_code                    csa_name  datum  ...  monitoring_objective  \\\n",
       "0      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
       "1      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
       "2      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
       "3      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
       "4      380  Mobile-Daphne-Fairhope, AL  NAD83  ...   POPULATION EXPOSURE   \n",
       "\n",
       "    open_date parameter_code    parameter_name  pl_probe_location  poc si_id  \\\n",
       "0  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
       "1  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
       "2  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
       "3  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
       "4  2010-05-17          43236  2-Ethyl-1-butene               None   10     7   \n",
       "\n",
       "   site_number state_code    State  \n",
       "0         0010         01  Alabama  \n",
       "1         0010         01  Alabama  \n",
       "2         0010         01  Alabama  \n",
       "3         0010         01  Alabama  \n",
       "4         0010         01  Alabama  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most of the columns have consistent values. State, County, and City values are consistent and are stored with title case\n",
    "# (first character of each word to uppercase and remaining to lowercase). The Address column values need to be converted \n",
    "# to title case. \n",
    "\n",
    "combined_df['address'] = combined_df['address'].str.title()\n",
    "\n",
    "# Check if the changes are applied using head() function\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is specific to counties and is using values from specific categories for each column, there are no outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('aqs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
